What is the meta oversight board?
	 Independent Body made by meta.
		 provides decisions on content moderation questions
		 ask broader questions about difficult content moderation problems
		 separate trust
		 Has trustees.
		 Cases and controversy on meta platforms (repeorted content)
			 they have recieved 2.5 million appeals
				 they have decided 67ish cases
					 75% overturn metas decisions
		they aim to uses certain difficult and hard cases to regulate on a larger scale.
		the difficult work is in the accompaning reccomendations instead of just letting content stay up or fall down.
			have given 250 ish reccommendations
			recomendations on policy changes and how automation is used
		the board is still an experiment, it is the first of its kind in the world.
		has recieved initial skepticism over the independednce of the board.
		They weigh in on the hardest and most consequential problems in public speech regulation
			Should Trump be removed
			Should covid misinformation be shared online
			should there be incitement of violence
			should there be government influence over platforms.
		They are in a very dynamic legal area.
		what is the normative framework that should govern social media, how should international [human rights] law govern the board and social media.
		the experience of the board has shown how a rights based network is essential in thinking through these problems
		basing it only on human rights law is insufficeint, since it can't moderate speech at scale.
		David Kay - Look Him Up
		Evelyn Duak - Look her up

Outline of where [human rights] norms get worked into boards decisions.
	They look at the 2011 coporate
	[UDHR]
	[PERD]
	[Convention on the Rights of the Child]
	[Convention on the Rights of Women]
	[1966 Covenant on Political and Civil Rights]
	every content decision is based on limitations on freedom of expression.
		has this been done in a ways that stasifies legal issues.
		by putting human rights in the centre of the argument, 
		at the core lies the dignity of every human person. - Dont make this overly utilitarian decisions, dont make it formulaic.
		Provide ethically cross-cultural vocabulary and reference point.
		Social media can't be contained within a speciic cultural context.
		There is an emphasis on "universal" human rights, not european human rights, not american human rights, universal.
		Establishes links to other human rights bodies
		these contribute to the boards success in protecting freedom of expression
		and balancing freedom of expression in relatijg to rights.

What has happened?
	meta has created a policy exception to satirical content.
	created translated policy version into different languages.
	Death to harmani allowed, increase in 30% use case in Iran.
	there is a track record of some noticable successes over the last three years.

Challenges that arise to the board?
	Some of the challenges arise in the gaps between a private company and a state actor.
	Conceptual gaps between the scope and operation of human rights law, and the scope and operation of restraint of human exppression through vast and complex automated systems.
	human rights try to push towards an individual focus.
	We are facing very diffuse goods, vast scale.
	Contrast between the coceptualisation of human rights.
	100m enforcement decisions a day on some platform.
	we are asking what are the derees and kinds of errors we are willing to tolerate, this is something that we would never ask of human rights.
	Shift in mentality towards a broader spectrum
	Human rights norms can be adapted flexibly to context and tradition due to its individualised context.
	Its hard to build in context into automatic moderation.
	How can we take account adequately of context.
	Its hard to apply the context from states to companies in the form of prevention of overlimitation of freedom of expression.
	It doesn't say when you should intervene, it just says  when not to.
	On what grounds should we say that meta has an affrimitave confirmation to intervene here, to limit this freedom of expression on thier platforms.
	What counts as Harm?
	What are the harms we need to be attentive too, how are they different on an online space, when compared to a human space.
	What are the adverse impacts that trigger the responsibilities of companies to prevent and intervene.
	Harms brought up would not usually be brought up on a human level.
	The speed of response for these harms, needs tohave the harms have a cumalitive value.
	There is complete empirical uncertantiy as to wether cumalitive harms actually exist.
	We cannot take a profilatic approach, since cumaltive harms can work in multiple directions simultaneously. 
	In a world wheere we are in a place of rising authoritarianism. Negative spillover from meta decisions can be hurtful

It can cause overvirtues in the methods of legalism.
	There is an emphasis of legalistic approaches in international human rights law.
	We need to make sure that we dont push towards legalism in content moderation.
	Legalism tries to substitute agressively comparing the issues at hand with proceduralism.
	Legalisim tends to push decisions towards proportionality, it leads to a high degree of expression.

Do these problems mean that the human rights paradigm is the wrong one for the meta oversight board?
	No 
		they push for them to think in a certain way when considering content moderation.
		They need to seperate how they apply human rights law towards content moderation, when compared to governments and states.
		When platforms depart from human rights, they should give full justification.
		We should return more systematically to the fundamental principles of which human rights law is derived.
		We should focus on increasingly positivised rules of application human rights law.
		This tryies to make them more real and more effective.
		We need to get back to the basics of human rights to understand how to contextualise this.
		We would benefit from investigating human rights at a higher level of plurality.
		We should not just think of human rights as decisions, but as a broad set of principles that can help us articulate common rules, through harmonising them with each other.
		We have largely lost the ideas of interdependece of Human rights, we need to work on this more
		What human rights principles should exist beyond those that fovern states in written law.
		How can we foster robust freedom of expresion across jurisdictional lines.
		We try to follow human rights norms, over human rights law, this is because it gives us less limitation, in trying to help the innovation of systemic development to aid in the automation of this kind of applied work.












Lets take a step back - Identify why this is such a difficult problem.
	Before the internet all of our ideas of regulating freedom of expression came from restricitng books.
	We no long "Think" before we publish 
		we no longer value that we need to be able to protect anything that can publish.
		there is an attention buisness model in VLIPs
		this meanss that there is a need to distribute information very quickly.
		This can lead towards the idea that language communication isn't properly moderated.
		The board only looks at something 3-6 months after it has been posted, this doesnt help the original post, since it usually has a "shelflife" of 48hrs
	we need to try to ensure that VLIPs can train both content moderators and algorithmic processors, to downscale language and communication that can be problematic.


[Article 20 Treaty 1966 Civil Rights and Political Rights]
	Article 10 EU Convention
	[1st Amendment] Rights
		Directed at State Power.

The USA is doing a horrible job at failing to try to reach a resonable way to regulate this space.

Overall the [section 230 approach] has been very useful in protecting human expression
the fact that we are all publishers is beneficial to human rights.

How do you deal with the fact America is an outlier in the Human Rights Community?
i.e 1st ammendment not covering hate speech.
	 We have acknowledged that the USA's approach is not beneficial, since it has a global reach.
	 It doesn't work
		 - We apply UN Standards.
	but...
		At a different level all of the ideas are brought in .
		They breakdown over an assesment of proportionality,
			How imminent should incitement be before we regulate against it? - Incitment means physical harm
	Should we have a pluralistic idea of an output, should we have multiple outputs depending on the proportionality of different state - have a look at subsidiarity and how it affects human rights law.
	so far we have only insisted on the factual differences in plurality, and inexplicit differnces.
	Meta's community guidlines are strictly an EU Article 19 based.
	UK Online Saftey Act - Royal Assent


Should meta make an exception on a restriction on post designed to solict an exchange of regulated drugs.
	context of health related drugs in sri lanka.


How do you see the accountability of tech companies on the actions of their users?
		None of the oversight board members believe that self-regulation is sufficient.
		Self Regulation is a piece of a larger system of accountability.
		You can't regulate this without a large amount of self-regulation.
		They are working on expanding accountability in the scope of this issue.

How does this work with the attention driven buisness plan that meta and other social media corporations are pushing.?
		There will be large questions about the scope of the buisness plan through the idea that there is needed other forms of regulatory accountability.
		

How do you position the oversight board when compared to the supreme court?
		We are not in an institutionalised object. 
		We are more like a n international human rights directive, not a supreme court.
		We have no checks and balances.
		It needs to be much more mediated.
		We need to think about the way that.
		We all know that the state is an amalgum of different conflicting interests.
		We need to leverage the overaching differneces in different forms of institutions
		In a company like Meta, there are some who are more supportive of the board, and there are those who are much more skeptical about the board.


We have always been interested in the state regulating the press
	 we have coregulation of broadcasters -ofcom
	 we have regulation of press
	 there are many states that want to regulate the internet out of existence.

Alot of the solutions to content moderation are going to be AI driven

can you reduce human rights decisions into an algorithm
Is it appropriate to turn human rights decisions to a non-human?



The weigh in on issues based on what role it could have.


They have tried to introduce a more open democratic opening. They convene stakeholder rountables on the harder cases.

What is the source of the obligations of the companies?
	Roots- Questions of Duty.

What is the dignitarian harm that hate speech produces?
	There is a certain kind of dignitarian harm that systematic hate speech brings.
	
The board does not fully work with algorithms
There are almost no areas where you can get a universal consentual agreement that that expression is so harmful.
Once you get to terrorist organisations you get isagreement about what should be moderated.



